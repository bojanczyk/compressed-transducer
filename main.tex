\documentclass{article}


\usepackage{macros}

\usepackage{enumitem}

\begin{document}

\title{Transducers on compressed strings}

\maketitle

\begin{abstract}
The question, whether the image $f(w)$ of a compressed string $w$ under a string function $f$ is still compressible in the sense that
the size of the compressed representation of $f(w)$ is polynomially bounded in the size of the compressed representation of $w$.
We investigate this question in the setting, where the compressed representation of $w$ is a straight line program (a context free grammar
that produces $\{w\}$) and $f$ is a polyregular function. We show that in this setting the above question has in general a negative answer, but a 
positive answer can be obtained for a subclass of polyregular functions -- the so-called rectangular polyregular functions -- which properly contains 
the class of regular 
functions. Finally, we
present a functional programming language that computes exactly the rectangular polyregular functions.
\end{abstract}

\section{Introduction}

% Mikolaj: I would prefer to avoid the term "big data", especially in a first sentence, otherwise my colleagues will complain that this is just buzzwording :) I guess people know that compression is important.
% Data compression is a core technology in computer science that has gained additional importance in the era of big data.
% For an introduction into classical compression techniques see  \cite{Say00}. 
The starting point for this work stems from the paradigm of {\em algorithmics on compressed data}. 
Its principal idea is to process data that is given in compressed form without first decompressing it and then operating on the uncompressed data.
There are three main applications for algorithms of this kind (see  \cite{Loh12survey} for a survey).
\begin{itemize}
\item  In many applications one has to combine compression and querying. A typical example 
is a genom database where DNA sequences are stored in compressed form and searched for specific patterns (e.g. genes).
This leads to so-called compressed text indices \cite{CNP21,FeMa05}
\item A compressed representation of the input data might reveal
certain regularities, which could be used to speed up an algorithm. This principle is 
known as {\em acceleration by compression}. An example can be found in \cite{LMWZiv07},
where Viterbi's algorithms for decoding  
hidden Markov chains is speeded up using compression.
\item Large and often highly compressible data may appear as 
intermediate data structures in algorithms. In such a situation, one may try to 
store a compressed representation of these intermediate data structures
and to process this representation. This may lead to more efficient 
algorithms. One example, which arises in group theory, is the compressed word problem:  checking if two compressed representations describe the same group element, see the surveys~\cite{BKLMNRS20,Loh14}.
\end{itemize}
We begin our investigation of algorithmics on compressed data by clarifying two aspects: (i)
what compressed representation of data is used and (ii)
what are the processing steps carried out on the compressed data? 


\paragraph{Grammar-based string compression.}
Let us first address question (i), which is about the compression format. In this paper we consider strings (words) that are compressed using context-free grammars: a \emph{grammar compression} of a string $w \in A^*$ is a context-free grammar which generates the string $w$ and no other strings (we will also shortly speak of a 
\emph{compression} of $w$). Syntactically, this can be ensured by only considering context-free grammars that are acyclic (there is no nonterminal $X$ and a non-empty derivation $X \Rightarrow^+ u$ such that $X$ appears in $u$) and where every nonterminal $X$ has
a unique production with left-hand side $Y$.
  An equivalent representation is a \emph{straight line program}, which is a sequence of instructions 
  of the form $x := a$ and $x := y \cdot z$ for variables $x,y,z$ and a terminal symbol $a$.
 The following straight line program generates the string $aaaa$:
\begin{lstlisting}
    x := a
    y := x $\cdot$ x
    z := y $\cdot$ y
\end{lstlisting}
The variables can be seen as non-terminals, and the variable $z$ in the last line can be seen as the starting non-terminal. 
Note that a straight line program corresponds to a context-free grammar in Chomsky normal form. We define the size of 
a straight line program as the number of instructions (or, equivalently, the number of non-terminals in the corresponding Chomsky
normal form grammar).
A straight line  program can achieve exponential compression, but not more: every program of size $n$ generates a string of length at most $2^n$.
It is well known that every string of length $n$ over an alphabet of size $\sigma$ can be generated by a straight line program of size
$\mathcal{O}(n / \log_\sigma n)$; see \cite[Proposition~3.1]{BerstelB87} where straight line programs are called word chains.

Although computing a straight line  program for a given string is not possible in polynomial time unless \textsf{P} = \textsf{NP} \cite[Theorem~1]{CLLLPPSS05},
there exist several compressors that achieve a good approximation of a smallest straight line program \cite{CLLLPPSS05,Jez15approx,Ryt03}.

Straight-line programs have been intensively used in algorithmics on compressed data. 
Algorithmic problems that can be solved in polynomial time on grammar compressed strings are for instance
checking equality \cite{HirshfeldJM94,MehlhornSU94,Pla94}, pattern matching \cite{KRS95,Jez15}, and membership in regular languages \cite{PlandowskiR99}; see the survey \cite{Loh12survey} for further details.
On the negative side, testing membership of a grammar compressed string in a context-free language (and even a fixed
visibly pushdown language) is a \textsf{PSPACE}-complete problem \cite[Theorem 9]{Lohrey11}.


\paragraph{String-to-string functions.}
We now come to the second question (ii): What are the processing steps carried out on the compressed data?
The most general option for processing compressed strings would be to allow arbitrary
 \emph{string-to-string functions}. A  string-to-string function is a function $f : A^* \to B^*$ where $A$ and $B$ are finite alphabets. 
We are interested in string-to-string functions that can be evaluated using compressions, i.e.~given a compression of the input, one can return a compression of the output, in deterministic polynomial time. This is described in the following definition.

\begin{definition}
    A string-to-string function $f : A^* \to B^*$ is called \emph{compatible with compression} if there is a deterministic polynomial time algorithm which does this: 
    \begin{itemize}
        \item \textbf{Input:} a compression of a string $w \in A^*$.
        \item \textbf{Output:} a compression of the string $f(w) \in B^*$.
    \end{itemize}
\end{definition}
% \begin{definition}[Compression lifting]
%     For a string-to-string function 
%     \begin{align*}
%     f : \Sigma^* \to \Gamma^*,
%     \end{align*} a  \emph{compression lifting} is any   $f'$ which makes the following diagram commute:
% \[
% \begin{tikzcd}
% \text{compressipon of $\Sigma^*$}
% \ar[r,"f'"]
% \ar[d,"\text{uncompress}"']
% &
% \text{compressions of $\Gamma^*$}
% \ar[d,"\text{uncompress}"]
% \\
% \Sigma^*
% \ar[r,"f"']
% & 
% \Gamma^*
% \end{tikzcd}
% \]
% We say that $f$ is \emph{compatible with compression} if it has a compression lifting which is computable in deterministic polynomial time.
% \end{definition}

Let us begin with some examples of functions that are compatible with compression, and some that are not. In the examples, we use straight line programs as the representation of compressions.

\begin{myexample}[Duplication]\label{ex:duplication}
    The string duplication function $w \mapsto ww$ is compatible with compression. The corresponding operation on straight line programs is to append one more line \texttt{x := y $\cdot$ y}, where \texttt{y} was the last variable used in the input program. 
\end{myexample}

\begin{myexample}[Reversal]\label{ex:reversal}
    String reversal is also compatible with compression. The corresponding operation on straight line programs is to reverse the order of concatenation in every line. 
\end{myexample}

\begin{myexample}[Squaring]\label{ex:squaring}
  Consider the squaring function illustrated as follows:
\begin{align*}
    123 \quad \mapsto \quad 123123123.
\end{align*}
This function  is compatible with compression. To implement squaring on  straight line programs, we write the code of the program twice, with the second copy using the output of the first copy instead of the character constants. 
\end{myexample}

\begin{myexample}[Exponential outputs] \label{ex:exp-output} This is a non-example, i.e.~a function that is not compatible with compression.
    Assume that the input and output alphabets have one letter only, and consider the function 
    \begin{equation} \label{exp-map}
    a^n \quad \mapsto \quad a^{2^n}.
    \end{equation}
    This function is not compatible with compression. The reason is that we can produce $a^{2^k}$ by a straight line program of size $k$.
    The  function \eqref{exp-map} maps $a^{2^k}$ to $a^{2^{2^k}}$ which requires a compression of size $2^k$. 
    Such a compression cannot be constructed in polynomial time from a compression of size $k$.
\end{myexample}

Characterizing the class of all string-to-string functions that are compatible with compression is a hopeless task. Therefore, we restrict
to string-to-string functions that can be computed by certain models of string transducers.
There will be three kinds of transducer models considered in this paper, which the define the following function classes:
\begin{align*}
\text{rational functions} 
\quad \subseteq \quad 
\text{regular functions}
\quad \subseteq \quad 
\text{polyregular functions.}
\end{align*}
Rational functions are computed by nondeterministic one-way transducers, whereas regular functions are computed by deterministic 
two-way transducers. Finally, polyregular functions are computed deterministic two-way transducers with pebbles. The regular and polyregular
functions have many equivalent characterizations \cite{polyregular-survey}; in this paper we will use characterizations based on closure properties of string-to-string functions.

We will first prove that the rational functions are compatible with compression and then extend this result to the regular functions using
a characterization of the latter class based on closure properties. In contrast, we will give an example of a 
polyregular function that is not compatible with compression. This leads to the question, which 
 polyregular functions are compatible with compression. This questions remain open, but we will define a natural class of functions that
is strictly located between the regular functions and the polyregular functions and that is compatible with compression. We call these
functions \emph{rectangular polyregular}; their definition is again based on closure properties.

In the second part of the paper we will investigate rectangular polyregular functions in more detail. In particular we will present a functional
programming language that computes exactly the rectangular polyregular functions.  This programming language is a fragment of the 
\emph{polyregular $\lambda$-calculus} from~\cite{polyregular-survey}.

\input{linreg}
\input{polyreg}
\input{combinators}
\input{blind}

\nocite{bojanczyk_recobook}
\bibliographystyle{plain}
\bibliography{bib}



\end{document}
